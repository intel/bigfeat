{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a graph that capture tpcds schema. Nodes: Tables; Edges: Tables are joinable; \n",
    "#       Edge value: join key\n",
    "\n",
    "# TODO: Add Pyhive and SQLAlchemy to the requirements\n",
    "# TODO: Add filtering of columns based on input from the user\n",
    "# TODO: Make a plan to understand how to do joins\n",
    "# TODO: Create a dictionary of columns to idx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhive import presto\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "from sql_formatter.core import format_sql\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "A database class built on top of sqlalchemy\n",
    "\"\"\"\n",
    "class DB:\n",
    "\n",
    "    def __init__(self, \n",
    "                 database = 'presto',\n",
    "                 ip = 'localhost', \n",
    "                 port = '8080', \n",
    "                 catalog = 'hive', \n",
    "                 schema ='tpcds_sf1_parquet' ):\n",
    "        connection_string = f'{database}://{ip}:{port}/{catalog}/{schema}'\n",
    "        self.engine = create_engine(connection_string)\n",
    "        self.cursor = self.engine.connect()\n",
    "    \n",
    "    def query(self, sql):\n",
    "        self.result = self.cursor.execute(text(sql))\n",
    "        return self.result\n",
    "    \n",
    "    def get_result(self,\n",
    "               limit = None,\n",
    "               format=\"pd\"):\n",
    "        \n",
    "        if format == \"pd\":\n",
    "            if limit == None:\n",
    "                return pd.DataFrame(self.result.all())    \n",
    "            \n",
    "            return pd.DataFrame(self.result.fetchmany(limit))\n",
    "        \n",
    "    \n",
    "db = DB()\n",
    "db.query(\"show columns from customer\")\n",
    "result = db.get_result()\n",
    "for column in result:\n",
    "    print(column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input\n",
    "    tables -- List of tables to generate feature maps from e.g., [web_sales,customer]\n",
    "    col_idx -- Optional: idx of columns corresponding to both tables e.g., [[0,1,2],[2,3,4]].\n",
    "                If none, use all columns in the feature map. \n",
    "Returns a SQL query as a string to generate dense feature maps\n",
    "\"\"\"\n",
    "\n",
    "def generate_dense_feature_map_query(db,\n",
    "                                     tables, \n",
    "                                     columns=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Check if table exists in columns\n",
    "    \"\"\"\n",
    "    \n",
    "    db.query(\"show tables\")\n",
    "    result = db.get_result()\n",
    "    \n",
    "    for table in tables:\n",
    "\n",
    "        if table not in list(result['Table']):\n",
    "            print(f'Table {table} does not exist!')\n",
    "            return -1\n",
    "\n",
    "    \"\"\"\n",
    "    Get list of columns from all tables\n",
    "    \"\"\"\n",
    "    \n",
    "    columns = []\n",
    "\n",
    "    for table in tables:\n",
    "\n",
    "        sql = f'SHOW columns FROM {table}'\n",
    "        db.query(sql)\n",
    "        columns.append(db.get_result())\n",
    "\n",
    "    all_columns = pd.concat(columns)\n",
    "\n",
    "    \"\"\"\n",
    "    Filter out all columns that are foreign keys\n",
    "    \"\"\"\n",
    "\n",
    "    all_columns = all_columns[~all_columns['Column'].str.contains('sk')]\n",
    "\n",
    "    # WASAY: Hash function goes here\n",
    "    print(all_columns)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Create list of idx and column names to build the map from\n",
    "    \"\"\"\n",
    "\n",
    "    # WASAY: Replace the name with the hash output\n",
    "\n",
    "    list_of_columns = list(all_columns['Column'])\n",
    "    list_of_idx = [str(i) for i in range(len(list_of_columns))]\n",
    "\n",
    "    \"\"\"\n",
    "    Create different subsets of the query\n",
    "    \"\"\"\n",
    "    create_query = 'df'\n",
    "    map_query = f'MAP(ARRAY[{\",\".join(list_of_idx)}],ARRAY[{\",\".join(list_of_columns)}])'\n",
    "    from_query = f'{\",\".join(tables)}'\n",
    "    where_query = ''\n",
    "\n",
    "    query = f'CREATE TABLE {create_query} AS SELECT {map_query} FROM {from_query} WHERE {where_query};'\n",
    "    print(format_sql(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dense_feature_map_query(db=db, tables=['customer','web_returns','web_sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
